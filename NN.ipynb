{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dims = [28 * 28, 4, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_back(dA, z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return dA * s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_back(dA, z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[z<=0] = 0\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(layer_dims):\n",
    "    L = len(layer_dims)\n",
    "    params = {}\n",
    "    for l in range(1, L):\n",
    "        params[\"w\" + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * math.sqrt(2/layer_dims[l-1])\n",
    "        params[\"b\" + str(l)] = np.zeros([layer_dims[l], 1])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_prop(params, x):\n",
    "    A_prev = np.array(x, copy = True)\n",
    "    m = x.shape[1]\n",
    "    L = len(params)//2\n",
    "    caches = []\n",
    "    for l in range(L - 1):\n",
    "        \n",
    "        w = params['w' + str(l+1)]\n",
    "        b = params['b' + str(l+1)]\n",
    "        \n",
    "        \n",
    "        assert(w.shape == (layer_dims[l + 1], layer_dims[l]))\n",
    "        assert(b.shape == (layer_dims[l + 1], 1))\n",
    "        assert(A_prev.shape == (layer_dims[l], m))\n",
    "            \n",
    "            \n",
    "        z = np.dot(w, A_prev) + b\n",
    "        cache = (A_prev, w, b, z)\n",
    "        A_prev = relu(z)\n",
    "        \n",
    "        \n",
    "        assert(z.shape == (layer_dims[l + 1], m))\n",
    "        \n",
    "        caches.append(cache)\n",
    "    \n",
    "        \n",
    "    w = params[\"w\" + str(L)]\n",
    "    b = params[\"b\" + str(L)]\n",
    "    \n",
    "    assert(w.shape == (layer_dims[L], layer_dims[L - 1]))\n",
    "    assert(b.shape == (layer_dims[L], 1))\n",
    "    assert(A_prev.shape == (layer_dims[L-1], m))\n",
    "    z = np.dot(w, A_prev) + b\n",
    "    \n",
    "    assert(z.shape == (layer_dims[L], m))\n",
    "    \n",
    "    cache = (A_prev, w, b, z)\n",
    "    AL = sigmoid(z)\n",
    "    \n",
    "    caches.append(cache)\n",
    "    return AL, caches\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    return -(np.sum(Y * np.log(AL) + (1 - Y) * np.log(1 - AL)))/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(AL, Y, caches):\n",
    "    m = Y.shape[1]\n",
    "    dA = np.divide(-Y, AL) + np.divide(1 - Y, 1 - AL)\n",
    "    assert(dA.shape == (layer_dims[-1], m))\n",
    "    grads = []\n",
    "    \n",
    "    L = len(caches)\n",
    "    A_prev, w, b, z = caches[L -1]\n",
    "    \n",
    "    dZ = sigmoid_back(dA, z)\n",
    "    dw = np.dot(dZ, A_prev.T)/m\n",
    "    db = np.sum(dZ, axis = 1, keepdims = True)/m\n",
    "    assert(db.shape == b.shape)\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(dZ.shape == z.shape)\n",
    "    dA_prev = np.dot(w.T, dZ)\n",
    "    dA = dA_prev\n",
    "    \n",
    "    grad = (dZ, dw, db, dA_prev)\n",
    "    grads.append(grad)\n",
    "    \n",
    "    \n",
    "    for l in reversed(range(L - 1)):\n",
    "        A_prev, w, b, z = caches[l]\n",
    "        \n",
    "        dZ = relu_back(dA, z)\n",
    "        dw = np.dot(dZ, A_prev.T)/m\n",
    "        db = np.sum(dZ, axis = 1, keepdims = True)/m\n",
    "        assert(db.shape == b.shape)\n",
    "        assert(dw.shape == w.shape)\n",
    "        assert(dZ.shape == z.shape)\n",
    "        dA_prev = np.dot(w.T, dZ)\n",
    "        dA = dA_prev\n",
    "        \n",
    "        grad = (dZ, dw, db, dA_prev)\n",
    "        grads.append(grad)\n",
    "        \n",
    "        \n",
    "    return grads\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(params, grads, learning_rate):\n",
    "    L = len(params)//2\n",
    "    grads.reverse()\n",
    "    \n",
    "    for l in range(L):\n",
    "        dZ, dw, db, dA_prev = grads[l]\n",
    "        params['w' + str(l + 1)] = params['w' + str(l + 1)] - (learning_rate * dw)\n",
    "        params['b' + str(l + 1)] = params['b' + str(l + 1)] - (learning_rate * db)\n",
    "\n",
    "        assert(params['w' + str(l + 1)].shape == (layer_dims[l + 1], layer_dims[l]))\n",
    "        assert(params['b' + str(l + 1)].shape == (layer_dims[l + 1], 1))\n",
    "        \n",
    "    return params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(params, x, y):\n",
    "    AL, caches = for_prop(params, x)\n",
    "    \n",
    "    y_prediction = np.where(AL<=0.5, 0, 1)\n",
    "    acc = 100 - (np.mean(np.abs(y_prediction - y)) * 100)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(trianx, trainy, testx, testy, layer_dims, num_iteration, learning_rate, print_cost):\n",
    "    params = initialize(layer_dims)\n",
    "    \n",
    "    costs = []\n",
    "    for i in range(1, num_iteration+1):\n",
    "        \n",
    "        AL, caches = for_prop(params, trainx)\n",
    "        cost = compute_cost(AL, trainy)\n",
    "        grads = back_prop(AL, trainy, caches)\n",
    "        params = optimize(params, grads, learning_rate)\n",
    "        \n",
    "        if i%100 == 0 and print_cost:\n",
    "            print(\"cost at iteration \", i, \": \", cost)\n",
    "            costs.append(cost)\n",
    "            \n",
    "    train_acc = predict(params, trainx, trainy)\n",
    "    test_acc = predict(params, testx, testy)\n",
    "    \n",
    "    print(\"Training accuracy: \", train_acc)\n",
    "    print(\"Test accuracy: \", test_acc)\n",
    "    \n",
    "    data = {\"params\": params,\n",
    "           \"costs\": cost,\n",
    "           \"train_acc\": train_acc,\n",
    "           \"test_acc\": test_acc}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"handwrittendata.pickle\", \"rb\") as pickle_in:\n",
    "    data = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['trainx', 'trainy', 'testx', 'testy'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = data['trainx']/255\n",
    "trainy = data['trainy']\n",
    "testx = data['testx']/255\n",
    "testy = data['testy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 80)\n"
     ]
    }
   ],
   "source": [
    "print(testx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at iteration  100 :  0.09466853566803857\n",
      "cost at iteration  200 :  0.05694995533714396\n",
      "cost at iteration  300 :  0.044569702542832594\n",
      "cost at iteration  400 :  0.03758984571085106\n",
      "cost at iteration  500 :  0.03288096699114577\n",
      "cost at iteration  600 :  0.02938873998385639\n",
      "cost at iteration  700 :  0.02663672692832822\n",
      "cost at iteration  800 :  0.024376965285457842\n",
      "cost at iteration  900 :  0.022467110264873198\n",
      "cost at iteration  1000 :  0.02081800308229185\n",
      "cost at iteration  1100 :  0.01937233530064329\n",
      "cost at iteration  1200 :  0.01809209341065612\n",
      "cost at iteration  1300 :  0.016949856670238482\n",
      "cost at iteration  1400 :  0.015922449545102576\n",
      "cost at iteration  1500 :  0.014993294282710706\n",
      "cost at iteration  1600 :  0.014148869252227074\n",
      "cost at iteration  1700 :  0.013378560443569023\n",
      "cost at iteration  1800 :  0.012673292750002516\n",
      "cost at iteration  1900 :  0.012025682118165591\n",
      "cost at iteration  2000 :  0.011429244730349834\n",
      "Training accuracy:  99.85007496251875\n",
      "Test accuracy:  98.75\n"
     ]
    }
   ],
   "source": [
    "d = model(trainx, trainy, testx, testy, [28 * 28, 4, 1], 2000, 0.05, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['params', 'costs', 'train_acc', 'test_acc'])\n"
     ]
    }
   ],
   "source": [
    "print(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.35032483758121\n",
      "97.5\n"
     ]
    }
   ],
   "source": [
    "print(d['train_acc'])\n",
    "print(d['test_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"NN ABClassifier result\", \"wb\") as pickle_out:\n",
    "    pickle.dump(d, pickle_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
